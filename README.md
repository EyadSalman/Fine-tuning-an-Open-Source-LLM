# ğŸ§  Fine-Tuning an Open Source LLM using LoRA

This project presents a complete pipeline to fine-tune a compact but powerful open-source language model â€” **TinyLlama-1.1B-Chat-v1.0** â€” using **LoRA (Low-Rank Adaptation)**. We train it on a public dataset of inspirational quotes to generate human-like motivational responses with minimal compute.

> Example Output:  
> **"You must be very brave, though I can only be very foolish.â€"I think the difference between people who are brave and those who are foolish is that the brave know when something is foolish and the foolish don't."**

---

## ğŸ¯ Objective

- Fine-tune a small-scale LLM with low compute using 4-bit quantization and LoRA
- Train on a simple instruction-style dataset (`Abirate/english_quotes`)
- Evaluate model performance using loss, perplexity, and qualitative generation
- Demonstrate instruction-tuned behavior through inference prompts

---

## ğŸ“š Dataset

- [Abirate/english_quotes](https://huggingface.co/datasets/Abirate/english_quotes)  
- 1000+ motivational quotes


---

## ğŸ§  Model & Training Setup

- **Base Model:** `TinyLlama/TinyLlama-1.1B-Chat-v1.0`
- **Parameters:** 1.1B
- **Quantization:** 4-bit (NF4, with `bitsandbytes`)
- **Fine-tuning method:** LoRA via `peft`

### LoRA Config
- `r = 16`
- `lora_alpha = 32`
- `dropout = 0.1`
- Target Modules: `q_proj`, `v_proj`, `k_proj`, `o_proj`

---

## ğŸ“‚ Project Structure
.
â”œâ”€â”€ FinetuningLLM.ipynb      # Full training notebook
â”œâ”€â”€ outputs/                 # Saved model checkpoints
â”œâ”€â”€ README.md                # Project documentation
â””â”€â”€ requirements.txt         # Library dependencies


